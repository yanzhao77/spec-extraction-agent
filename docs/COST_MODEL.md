# 内部成本模型分析

**版本:** 1.0

**注意：** 本文档仅用于内部成本分析和定价参考，不作为对外的计费依据。实际计费以`BILLING_MODEL.md`中定义的“按次调用”为唯一标准。

---

## 1. 成本构成

单次API调用的主要可变成本来自于**大型语言模型（LLM）的API调用费用**。固定成本（如服务器、网络）在此模型中暂不考虑。

---

## 2. LLM Token消耗分析

智能体的执行过程涉及多个阶段的LLM调用，主要包括：

1.  **规划阶段 (PLANNING):** 对文档块进行分析，制定抽取计划。
2.  **抽取阶段 (EXTRACTION):** 根据计划，从文档块中抽取结构化信息。
3.  **修复阶段 (REPAIR):** 当校验失败时，对错误的条目进行修复。

### Token消耗估算 (基于Gemini 2.5 Flash)

| 阶段 | 输入Token (Input) | 输出Token (Output) | 说明 |
| :--- | :--- | :--- | :--- |
| **规划** | 1,000 - 3,000 | 200 - 500 | 取决于文档块的大小和复杂性 |
| **抽取** | 2,000 - 5,000 | 500 - 1,500 | 主要的Token消耗环节 |
| **修复 (单次)** | 500 - 1,000 | 100 - 300 | 每次修复尝试的额外成本 |

### 单次API调用的典型Token范围

| 场景 | 总输入Token (估算) | 总输出Token (估算) | 总Token (估算) |
| :--- | :--- | :--- | :--- |
| **最小调用 (简单文档，无修复)** | ~3,000 | ~700 | **~3,700** |
| **平均调用 (中等文档，少量修复)** | ~6,000 | ~1,500 | **~7,500** |
| **最大调用 (复杂文档，多次修复)** | > 10,000 | > 2,500 | **> 12,500** |

---

## 3. 自我修复阶段的额外成本

**自我修复是成本波动的主要因素。**

- 每当智能体进入`REPAIR`状态，它都会为每个失败的条目发起一次额外的LLM调用。
- 如果一次API调用中有5个条目需要修复，并且每个都需要2次尝试才能成功，那么将产生`5 * 2 = 10`次额外的LLM调用。

**成本影响:**

- 修复阶段可能导致单次API调用的成本增加 **50% 到 200%**。
- 我们的“按次调用”定价模型已经将这种平均修复成本考虑在内，从而为客户提供一个固定的、可预测的价格。

---

## 4. 成本控制与优化策略

- **模型选择:** 优先使用`gemini-2.5-flash`等高性价比模型。
- **Prompt优化:** 持续优化各阶段的Prompt，以减少不必要的Token使用。
- **智能规划:** 在`PLANNING`阶段识别出不相关的文档块，直接跳过，从而节省`EXTRACTION`阶段的成本。
- **修复策略:** 优化`REPAIR`阶段的Prompt，提高首次修复的成功率，减少重试次数。

---

## 5. 定价参考

基于上述Token消耗估算，并假设LLM提供商的定价为 ¥0.01 / 1k tokens，我们可以估算单次调用的平均成本：

`平均成本 = 7,500 tokens / 1,000 * ¥0.01/k-token = ¥0.075`

考虑到修复阶段的成本波动和一定的利润空间，将单次API调用的定价设置在 **¥0.40 - ¥0.60** 的范围内是合理的。这为我们提供了足够的缓冲来覆盖极端情况下的高成本调用。
